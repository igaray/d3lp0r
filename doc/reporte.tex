\documentclass{llncs2e/llncs}

% \usepackage{makeidx}  % allows for indexgeneration
\usepackage{verbatim}


\title{An Argumentative Approach for a BDI Agent} % tentativo

% \author{Iñaki Garay\inst{1} \and 
        % Diego Marcovecchio\inst{2} \and
        % Leonardo Molas\inst{3} \and
        % Emiliano Montenegro\inst{4} \and
        % Fernando Sisul\inst{5} \and
        % Manuel Torres\inst{6}
        % }
        
\author{Iñaki Garay \and 
        Diego Marcovecchio \and
        Leonardo Molas \and
        Emiliano Montenegro \and
        Fernando Sisul \and
        Manuel Torres
        }
        
\institute{Universidad Nacional del Sur}

\begin{document}


\frontmatter          % for the preliminaries

\maketitle

\begin{comment}
\pagestyle{headings}  % switches on printing of running heads
\addtocmark{Hamiltonian Mechanics} % additional mark in the TOC

= Technical Report

figuras
- la arquitectura del agente
- la arquitectura del programa
- ejemplo del fog of war y coloreo

meter una buena explicacion de la arquitectura bdi en la parte de diseño
\end{comment}


\begin{abstract}
    This report presents the design and results of the d3lp0r multi-agent system 
    developed by the LIDIA team for the 2011 Multi-Agent Programming Contest.
    The d3lp0r agents use a BDI architecture extended with planning and 
    argumentation (via Defeasible Logic Programming) to model a cooperating team 
    operating in a dynamic and competitive environment.

    In particular, the main goal of this report is to describe the chosen 
    architecture, the communication scheme and the way argumentation was put to 
    use in the agent's reasoning process and the technical details thereof.
\end{abstract}

\begin{comment}
{
    This paper presents the Argonauts multi-agent framework which was developed as 
    part of a one year student project at Technische Universität Dortmund. The 
    Argonauts framework builds on a BDI approach to model rational agents that act 
    cooperatively in a dynamic and indeterministically changing environment. 
    However, our agent model extends the traditional BDI approach in several 
    aspects, most notably by incorporating motivation into the agent’s goal 
    selection mechanism. The framework has been applied by the Argonauts team in 
    the 2010 version of the annual multi-agent programming contest organized by 
    Technische Universität Clausthal. In this paper, we present a high-level 
    specification and analysis of the actual system used for solving the given 
    scenario. We do this by applying the GAIA methodology, a high-level and 
    iterative approach to model communication and roles in multi-agent scenarios. 
    We further describe the technical details and insights gained during our 
    participation in the multi-agent programming contest.     

    In this article we report on the JIAC V team for the agent programming 
    competition 2009, going through the different phases of development and 
    describing the JIAC V agent framework. Based on an iterative approach, we 
    identified and implemented different agent roles. While there is no explicit 
    team concept, the agents cooperate by informing each other of their 
    perceptions and intentions, which leads to emergent team behavior which very 
    dynamically and flexibly reacts to the state of the game. 
}
\end{comment}

% == Introduction
\section{Introduction}

    The LIDIA (Laboratorio de Investigación y Desarrollo en Inteligencia 
    Artificial, Artificial Intelligence Research and Development Laboratory) 
    research group was established in 1992 in the Universidad Nacional del Sur. 
    The d3lp0r team was formed incorporating 6 graduate students, 2 Ph.D. students 
    and 3 professors. The undergraduate students fully developed the system, while 
    the Ph.D. students and professors provided guidance. The group's main 
    motivation was to apply argumentation via defeasible logic programming (DeLP) 
    in a BDI based agent, in the context of a multi-agent gaming situation, and to 
    test the integration of the different technologies used.

\begin{comment}
    
PREGUNTAS {
1. What was the motivation to participate in the contest?
2. What is the history of the team?
3. What is the name of your team?
4. How many developers and designers did you have?  At what level of education 
are your team members?
5. From which field of research do you come form?  Which work is related?
}

== Preliminaries

\end{comment}

\section{Preliminaries}

    The whole d3lp0r system was developed in the context of MAPC 2011 (footnote?). 
    The game's scenario was represented by an undirected graph, in which every 
    node was a valid location (with a predefined associated value), and edges 
    labeled with costs that indicated how much energy was drained if an agent 
    walked through the edge.

    Every match consisted of two rival teams, in which every team had a set of 
    agents with different preestablished roles (Explorer, Saboteur, Repairer, 
    Sentinel and Inspector). Every agent role had particular characteristics 
    (Energy, Health, Vision range), and determined the kind of actions that the 
    agent could perform.

    Match simulations took place in steps; in every step, each team was awarded 
    with points determined by the state of the simulation; the team's agents 
    received percepts with partial information about the current simulation state, 
    and had a discrete amount of time to make a decision about their actions; at 
    the end of the match, the team with the most points was the winner.

    In order to earn points, each team's agents should position themselves in the 
    map so that they formed "zones" (zones were determined by an algorithm 
    specified by the organizers). Other special situacions, such as earning 
    different achievements, could also increase the team's points.


    Si nos quedamos cortos, explicamos DeLP.

% == System Analysis and Design
\section{System Analysis and Design}

\begin{comment}

PREGUNTAS {
1. If some multi-agent system methodology such as Prometheus, O-MaSE, or 
Tropos was used, how did you use it? 
   If you did not what were the reasons?
2. Is the solution based on the centralisation of coordination/information on 
a specific agent?
   Conversely if you plan a decentralised solution, which strategy do you plan 
to use?
3. What is the communication strategy and how complex is it?
4. How are the following agent features considered/implemented: autonomy, 
proactiveness, reactiveness?
5. Is the team a truly multi-agent system or rather a centralised system in 
disguise?
6. How much time (man hours) have you invested (approximately) for 
implementing your team?
7. Did you discuss the design and strategies of your agent team with other 
developers? 
   To which extent did your test your agents playing with other teams?
}

\end{comment}

- Scenario analysis

    sacarlo del enunciado, resumirlo

- Arquitectura del agente
- Cooperation model

    An agent architecture was developed based on the BDI model.

    algo parecido a esto:

    Since the desires have an important impact on the possible intentions that an 
    agent will pursue, our approach focuses on refining the way desires are 
    generated.

    poner algo que justifique esto, y refrasear esto:

    sale de las prioridades de las metas

    This results in a less reactive and more autonomous way in which an agent acts.

    Since the intentions specified for the agents are simple, the need for 
    predefined plans or a planning component to generate a sequence of actions 
    from an intention.
    
    las intenciones son muy simples, reduciendo la necesidad de un planificador

    The solution follows a decentralised architecture in which agents run 
    completely decoupled in different processes while sharing nothing. Percepts 
    are communicated among agent members of the team via a broadcast mechanism 
    developed as part of the multi-agent system. This design was chosen for its 
    minimal complexity.

    Agents are completely autonomous meaning that decision-making takes place 
    individually at the agent level, with no intervention from human operators or 
    a central intelligence agency within the system, and that decisions made by an 
    agent are influenced solely by the current simulation state and the results of 
    previous steps.

    Our intention-based agents generate many possible desires in most of the 
    turns, and selects the best they can find, given their knowledge of the world. 
    They try to accomplish that intention, for several turns, until they finish, 
    or they find another reason to stop, and recalculate their intention.

    Every turn, the obtained percept is used to decide which intention is going to 
    be selected (when the agent hasn't got any), or it's used to decide whether it 
    is necessary to carry on the actual intention, or recalculate it. This happens 
    when the intention has been achieved (by the agent or other teammate), when 
    it's no longer necessary, when something else may be more important to do, or 
    when the agent is in danger.

    Experience from a previous instance of the MAPC was shared with our teams by 
    members of the ARGONAUTS team from Universität Dortmund. Although the initial 
    plan was to run tests against other agent teams prior to the competition, time 
    constraints made this impossible.

    No design methodology specific to multi-agent systems was used. However, 
    development was conducted using a simplified XP (extreme programming) 
    methodology. 

% == Software Architecture

\section{Software Architecture}

\begin{comment}

PREGUNTAS {
1. Which programming language did you use to implement the multi-agent system?
2. Did you use multi-agent programming languages? Why or why not to use a 
multi-agent programming language?
3. How have you mapped the designed architecture (both multi-agent and 
individual agent architectures) to programming codes i.e., how did you 
implement specific agent-oriented concepts and designed artifacts using the 
programming language?
4. Which development platforms and tools are used? How much time did you 
invest in learning those?
5. Which runtime platforms and tools (e.g. Jade, AgentScape, simply Java, 
....) are used? How much time did you invest in learning those?
6. What features were missing in your language choice that would have 
facilitated your development task?
7. What features of your programming language has simplified your development 
task?
8. Which algorithms are used/implemented?
9. How did you distribute the agents on several machines? And if you did not 
please justify why.
10. To which extend is the reasoning of your agents synchronized with the 
receive-percepts/send-action cycle?
11. What part of the development was most difficult/complex? What kind of 
problems have you found and how are they solved?
12. How many lines of code did you write for your software?
}

\end{comment}

    The agent system was implemented using Python 2.7 and SWI Prolog 5.10.5. DeLP, 
    a defeasible logic language, was used as a service within Prolog.

    Language integration was achieved using the pyswip library, to call Prolog 
    from Python.

    No multi-agent programming languages/patforms/frameworks were used due to 
    previous experience indicating a general lack of flexibilty, and a lack of 
    familiarity on behalf of the development team.

    Aca hay que poner como cada parte del dibujito original de leo a codigo.

    The perception is processed by the Python program, that parses the XML. Then, 
    it sends it to the Percept Server, that also receives all the information sent 
    by its teammates. This is a centralised server that every step merges all 
    perceptions, and delivers them back to the agents.

    Now, with a more complete version of the world, the Python code asserts all 
    the perception into Prolog, then querying it for the next action to be 
    executed. 

    The Prolog part handles all the decision taking, argumentation, and planning. 
    It returns the action binded to a variable to Python, that then generates with 
    it an XML to be sent to the server.

    Both Linux and the Windows operating system were used as development 
    platforms, since the language runtimes chosen for implementation were 
    portable. Some caveats were encountered however.

    We used git as our revision control system. In general, we did not spend much 
    time in learning it, since some of us had already worked with it.

    Python and Prolog were well-known at the start of the project, and were chosen 
    for precisely those reasons.

    We also selected our languages for their flexibilty, in order to not have this 
    problem.

    Python's amenity to rapid application development and 'batteries-included 
    philosophy' facilitated implementing the communication layer to the MASSimg 
    server, parsing of peceptions, rapid addition of planned features and bug 
    correction.

    We made use of Prolog's declarate nature to model states of the world, and it 
    also made more straightforward to implement search algorithms.

    Search algorithms, as Uniform Cost Search, and Depth First Search were 
    implemented in Prolog.

    The zone-coloring algorithm was also implemented in Prolog.

    The implementation of Defeasible Logic Programming (DeLP) by the LIDIA was 
    used for the deliberative process.

    Initial plans were to distribute agents on several machines. Each agents runs 
    as a separate process, and communicates with others via TCP sockets. After 
    some experience agents were run on one machine. Having the choice was a 
    benefit of the proposed design.

    Reasoning takes place within the perceive-act cycle.

    MANULON

    Seteo de beliefs.

    Tamaño de la KB de los agentes.

    Sincronizacion.

    Optimizacion.

    The most difficult problems were related to optimization. Much of our time has 
    been spent in reducing the complexity of our algorithms, and the times they 
    are called.

    For the coloring algorithm, we added several improvements, for both 
    optimization and correctness. In essence, since we only had a incomplete 
    version of the full map in every step, we added the concept of "fog of war" to 
    the agents, assuming always in a pessimistic way. 

    For both search algorithms, the Depth First Search and the Uniform Cost 
    Search, we added conditions that could cut several branches, when they were 
    expanding to unwanted nodes. This conditions were set by the caller, since 
    they depend on the context of the problem.

    For the UCS, we first used a simple stack, implemented with a list, to keep 
    track of the frontier, because of Prolog's inability to work with arrays, that 
    would have allowed us to develop a heap data structure, to be used in a 
    priority queue. Lately, we found a Prolog library that implemented this data 
    structure, and the migration was pleasently straightforward.

    Finally, for this last algorithm also, we added an important optimization, 
    that allowed us to call several times to it, with the virtual cost of only one 
    call. It was done using memoization, and a more thoughtful invocation.

    Total LOC is 5842. 

    ``Infrastructure'' : 

    ``Reasoning'' :

% == Stategies, Details, and Statistics

\section{Stategies, Details, and Statistics}

    The main strategy of the team consists of detecting profitable zones from the 
    explored vertices, and positioning the agents correctly to maintain, defend 
    and expand the zones.

    On each perceive/act cycle, agents receive the percept from the MASSim server, 
    separate the information which will remain private and which will be shared. 
    The public part of the percept is sent to the percept server, which performs a 
    union of all percept and send the difference back to each agent. After 
    receiving the joint percept, the agents enter a belief setting page, and later 
    an argumentation phase.

    Once the agent's action has been determined by argumentation and planning, it 
    is sent to the MASSim server.

    Agents make no assumption about the map topology. They will prefer higher 
    valued nodes over lower ones.

    Some functionality provided by the eismassim library was reimplemented in a 
    connection library in python.

    Agent recover their assigned role from the simulation start message, and 

    If an agent is not being part of any zone, it tries to regroup with a partner. 
    When a zone is formed, and the agent is part of it, for each potentally 
    beneficial neighbor node, the agent calculates how much points would they win 
    if it moves, and that information is used by the decision taking module.

    If the expansion intention explained is selected and carried on, then a new 
    better zone is implicitly conquered.

    Both attacking and defense are implicitly implemented. Sabouteurs attack 
    enemies that are near, so they might attack them if they enter our team's 
    zone, as well as when they are in their zone. Any other agent of another role
    can go to a node that has, for example, two agents, one for each team, in order
    to expand the zone, occupying the contested node, and implicitly defending it.
    

    Our agents do not change their behavior during runtime. It is actually very 
    easy to add this feature, but we had not enough time to implement this.

    Path planning is implemented with an Uniform Cost Search. What we tried to 
    minimize was the amount of steps required to achieve the goal, rather than the 
    spent energy. The returned result is the list of actions to be done, rather 
    than the list of nodes.
    
    Since this algorithm can be called several times in one step, given that the 
    actual amount of steps spent by an intention is taken under consideration by 
    the decision-taking module, it was crucial to perform several optimizations in 
    it. In the end, this allowed us to run all the agents in a single machine, 
    during the competition.

    Agents follow a list of predefined buying actions, when the necessary amount 
    of money is reached.
    
    Many different approaches were considered, i.e. a more thoughtful one, having 
    in consideration the amount of deaths, of our team, and of our enemy. However,
    this simple approach was the most easy to implement, and it was proven that it
    was the most succesful one.

    Agents followed a list of predefined buying actions, when the necessary amount 
    of money was reached.

    Our agents did not have achievements in consideration. However, they managed 
    to achieve a significant number of them, since this behavior was implicitly 
    implemented.

    The agents make plans as long as the selected intention requieres. This may 
    sound excesive, but the possible goals were previously selected for their 
    potential, taking in consideration their distance (in nodes, not in actions).

    However, plans are recalculated in every step. This decision was made taking 
    in consideration the fact that in the steps that we do not need to 

\begin{comment}
    
PREGUNTAS {
1. What is the main strategy of your team?
2. How does the overall team work together? (coordination, information 
sharing, ...)
3. How do your agents analyze the topology of the map? And how do they exploit 
their findings?
4. How do your agents communicate with the server?
5. How do you implement the roles of the agents? Which strategies do the 
different roles implement?
6. How do you find good zones? How do you estimate the value of zones?
7. How do you conquer zones? How do you defend zones if attacked? Do you 
attack zones?
8. Can your agents change their behavior during runtime? If so, what triggers 
the changes?
9. What algorithm(s) do you use for agent path planning?
10. How do you make use of the buying-mechanism?
11. How important are achievements for your overall strategy?
12. Do your agents have an explicit mental state?
13. How do your agents communicate? And what do they communicate?
14. How do you organize your agents? Do you use e.g. hierarchies? Is your 
organization implicit or explicit?
15. Is most of your agents’ behavior emergent on and individual and team level?
16. If your agents perform some planning, how many steps do they plan ahead?

}

\end{comment}

    The only organization that the agents have is the proper given by the 
    environment, which is the roles. 
    
    Refering to our actual programming, all the agents have a strong core of common
    code, which is:
    \begin{itemize}
        \item all the Python part, that servers as a receive-percepts/send-action client 
        of the server,
        
        \item the Percet Server,
        
        \item an important part of the Prolog code, including all the utilities used, the
        implementation of the BDI architecture, the structure of the 
        decision-taking module, and a considerable part of the arguments used, that
        are common to all the roles.
        
    \end{itemize}
        
    Apart from all this, each role has a couple of separate files, that have 
    specific code, including the arguments used in the decision-taking module, and
    the setting of the beliefs needed for those arguments. Here is where the 
    individual behavior is set, since the specific actions that can be done by each
    role are being had in consideration here.
    
    Specific values for the decision-taking module for each role are also included
    in these files, and this is what can make that agents of different role act 
    differently, faced to the same situation, according to our judgment.
    
    These separation is negligible, having in consideration the amount of code 
    written for the agents, and may be near a 5% of it. However, this has proven to
    be more than enough to modify considerably the behavior of the agents, thanks to
    the non-monotonic nature of DeLP, the argumentation language used in the 
    decision-taking module.

% == Conclusion

\section{Conclusion}

1. What have you learned from the participation in the contest?
2. Which are the strong and weak points of the team?

    Our team is formed by a group of friends, so a strong point in the developing 
    proccess would have been the cohesion and comradeship. We had also worked 
    together, in university's projects as well as outside them, in small freelance 
    projects, so we well knew what to expect from each other, and each member's 
    capabilities. 

    Several events in the developing proccess had depend from this bond, i.e. the 
    deployment. We could not connect to the server in the test matches from our 
    university, because of several network problems. Just a couple of days before 
    the competition, we decided to connect all from one of our partner's house, 
    who had the better infrastructure (connection to Internet, and space in his 
    department). This may seem stranger given the fact that we had to spent all 
    night working and testing there, so for a week the headquarters for our team 
    also became our home.

    However, we had many problems. Many of them were related with our lack of 
    professionality, and lack of experience working in a big project. For example, 
    we had problems simple but annoying problems, such as the encoding of our 
    source files, or having different versions of the programs we used to program
    installed in our computers.

3. How suitable was the chosen programming language, methodology, tools, and 
algorithms?

    We are really grateful with our decisions involving programming languages, 
    tools and algorithms. Of course, we had many problems, and much time was spent 
    deciding what to choose, but having all the proccess in consideration, we may 
    had took the right calls. We should thank the great education given by our 
    university (Universidad Nacional del Sur), and a great mentoring from our 
    professors.

4. What can be improved in the context for next year?

    Many things should and will be improved for next year competence. We had 
    gained an important amount of knowledge, capability and experience, that shall 
    help us in all aspects of the developing proccess, not to mention the 
    important amount of code already written, and all the good decisions already 
    made.

    In particular, we now know the importance of all the testing actually needed 
    for this sort of competition, not only in a virtual environment, as we did, 
    but also in the real context of the contest. There were several hotfixes that 
    were written and deployed at the same time we were facing our competitors, in 
    all but the last day of competition, in which we already had everything in 
    consideration and control.

5. Why did your team perform as it did? Why did the other teams perform 
better/worse than you did?

6. Which other research fields might be interested in the Multi-Agent 
Programming Contest?


7. How can the current scenario be optimized? How would those optimization pay 
off?

    Many optimizations ocurred to us for the scenario, and the contest in general. 
    For example, more information for the nodes, including something useful for a 
    directed search (i.e., absolute coordinates), would help in the implementation 
    of a A* search, that would decrease the execution times.

    Strategically, the early dominion of the center area played an important part 
    of a good candidate to win a match. It would be useful to try other 
    variations, such as making the borders more important, or others shapes of the 
    map, such as stretched, in form of V, X, O, etc. This would benefit teams that 
    explicitly and thoughtfully look for and conquer good zones, rather than 
    benefiting teams that assume that only one good zone exists, and it's in the 
    middle of the map.

    A more informing/informational/apprising? feedback from the server would be 
    appreciated, specially involving errors. This is important for a better and 
    quicker detection of bug involving the communication, i.e. problems with the 
    connection, files sent.

    Finally, we think it will be really helpful for all that we had test matches 
    in a more early stage, in order to have more time to correct errors in the 
    client. Many of us reimplemented the eismassim module, so we are vulnerable to 
    many errors that were difficult to foresee. Early testing would help with 
    that, and detecting infrastructure issues, such as network problems.
    
\end{document} 