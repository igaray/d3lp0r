\documentclass{llncs2e/llncs}

% \usepackage{makeidx}  % allows for indexgeneration
\usepackage{verbatim}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{bibentry}
\usepackage[numbers]{natbib}

\title{An Argumentative Approach for a BDI Agent} % tentativo
        
\author{I\~{n}aki Garay \and      % igarai@gmail.com
        Diego Marcovecchio \and   % diegomarcov@gmail.com
        Leonardo Molas \and       % leos.molas@gmail.com
        Emiliano Montenegro \and  % emm.montenegro@gmail.com
        Fernando Sisul \and       % fsisul@gmail.com
        Manuel Torres \and        % jmtorresluc@gmail.com
        Sebastián Gottifredi \and % sebastian.gottifredi@gmail.com
        Alejandro García \and     % ajg@cs.uns.edu.ar
        Diego Martínez \and       % dcm@cs.uns.edu.ar
        Guillermo Simari          % grs@cs.uns.edu.ar
        }

\institute{Universidad Nacional del Sur}

\begin{document}

\maketitle

\begin{comment}
\pagestyle{headings}  % switches on printing of running heads
\addtocmark{Hamiltonian Mechanics} % additional mark in the TOC
figuras
- la arquitectura del agente
- la arquitectura del programa
- ejemplo del fog of war y coloreo
meter una buena explicacion de la arquitectura bdi en la parte de diseño

- arquitectura
- argumentacion
- estrategias
- percept server
\end{comment}

\begin{abstract}
    This report presents the design and results of the d3lp0r multi-agent system 
    developed by the LIDIA team for the 2011 Multi-Agent Programming Contest.
    The d3lp0r agents use a BDI architecture extended with planning and 
    argumentation (via Defeasible Logic Programming) to model a cooperating team 
    operating in a dynamic and competitive environment.

    In particular, the main goal of this report is to describe the chosen 
    architecture, the communication scheme and the way argumentation was put to 
    use in the agent's reasoning process and the technical details thereof.
\end{abstract}

\section{Introduction}

    The LIDIA (Laboratorio de Investigación y Desarrollo en Inteligencia 
    Artificial, Artificial Intelligence Research and Development Laboratory) 
    research group was established in 1992 at the Universidad Nacional del Sur. 
    The d3lp0r team was formed incorporating six graduate students, two Ph.D. 
    students and three professors. The undergraduate students fully developed the 
    system, while the Ph.D. students and professors provided guidance. The group's 
    main motivation was to apply argumentation via defeasible logic programming 
    (DeLP) in a BDI based agent, in the context of a multi-agent gaming situation, 
    and to test the integration of the different technologies used.

    Experience from a previous instance of the MAPC was shared with our teams by 
    members of the ARGONAUTS team from Universität Dortmund. Although the initial 
    plan was to run tests against other agent teams prior to the competition, time 
    constraints acted against this.

\begin{comment}
PREGUNTAS {
1. What was the motivation to participate in the contest?
2. What is the history of the team?
3. What is the name of your team?
4. How many developers and designers did you have?  At what level of education 
are your team members?
5. From which field of research do you come form?  Which work is related?
}
\end{comment}

\section{Preliminaries}

    The \texttt{d3lp0r} system was developed in the context of the 2011 edition 
    of the Multi-Agent Programming Contest hosted by the University of 
    Clausthal. 

    The simulation scenario is represented as an undirected graph, in which 
    nodes are valid agent locations weighted by value, and edges are valid
    transitions weighted by cost. 
    Agent state includes energy, health, and strength parameters. Agent percepts
    include visible nodes, edges, and other agents. 
    Each agent is assigned a role in the simulation (Explorer, Saboteur,
    Repairer, Sentinel and Inspector) which determines its valid actions and
    initial maximum values for the agent state parameters. 
    Actions in general have an energy cost, movement action costs depend on edge
    weights, successful attack actions decrease enemy agent's health subject to
    a strength comparison. Certain actions may cause further information to be
    included in subsequent percepts. 

    A match consists of several simulations, each simulation proceeds as
    a series of steps. In each step, each agent is provided with a percept with
    partial information about the current simulation state and is
    queried for its action. 

    The goal is to maximize the score function each step. A team is awarded
    points according to the value of the nodes controlled by the team, and
    in addition certain achievements. Agents may control more nodes than 
    those they are positioned in by forming zones, groups of nodes under the
    influence of a team determined by a graph coloring algorithm specified in
    the scenario description. 

    The final score for a team is the sum of points over all steps; at the end
    of the match, the team with the most points is the winner.

\section{System Analysis and Design}

\begin{comment}
PREGUNTAS {
1. If some multi-agent system methodology such as Prometheus, O-MaSE, or 
Tropos was used, how did you use it? 
   If you did not what were the reasons?
2. Is the solution based on the centralisation of coordination/information on 
a specific agent?
   Conversely if you plan a decentralised solution, which strategy do you plan 
to use?
3. What is the communication strategy and how complex is it?
4. How are the following agent features considered/implemented: autonomy, 
proactiveness, reactiveness?
5. Is the team a truly multi-agent system or rather a centralised system in 
disguise?
6. How much time (man hours) have you invested (approximately) for 
implementing your team?
7. Did you discuss the design and strategies of your agent team with other 
developers? 
   To which extent did your test your agents playing with other teams?
}
\end{comment}

    Regardless of the many man-hours dedicated to design, in the early stages of
    the competition, the development team's lack of experience in multi-agent
    systems made necessary several changes and additions. 
    Despite this, our approach was more than satisfying, resulting to be
    modular, correct and in close correspondence with the literature.

\subsection{Agent Design}

    The solution follows a decentralised architecture in which agents run 
    completely decoupled in different processes while sharing nothing. Percepts 
    are communicated among agent members of the team via a broadcast mechanism 
    developed as part of the multi-agent system. This design was chosen for its 
    minimal complexity.

    Agents are completely autonomous meaning that decision-making takes place 
    individually at the agent level, with no intervention from human operators or 
    a central intelligence agency within the system, and that decisions made by an 
    agent are influenced solely by the current simulation state and the results of 
    previous steps.
    The agent architecture developed is based on the BDI model \cite{Rao:1991}, 
    and is explained in detail in further sections.

    No design methodology specific to multi-agent systems was used. However, 
    the implementation was conducted using a simplified XP (extreme programming) 
    methodology.

\begin{comment}
    algo parecido a esto:

        Since the desires have an important impact on the possible intentions that an 
        agent will pursue, our approach focuses on refining the way desires are 
        generated.

    This results in a less reactive and more autonomous way in which an agent acts.

    Since the intentions specified for the agents are simple, the need for 
    predefined plans or a planning component to generate a sequence of actions 
    from an intention.

    Our intention-based agents generate many possible desires in most of the 
    turns, and selects the best they can find, given their knowledge of the world. 
    They try to accomplish that intention, for several turns, until they finish, 
    or they find another reason to stop, and recalculate their intention.

    Each turn, the obtained percept is used to decide which intention is going to 
    be selected (when the agent hasn't got any), or it's used to decide whether it 
    is necessary to carry on the actual intention, or recalculate it. This happens 
    when the intention has been achieved (by the agent or other teammate), when 
    it's no longer necessary, when something else may be more important to do, or 
    when the agent is in danger.
\end{comment}

\section{Software Architecture}

\begin{comment}
PREGUNTAS {
1. Which programming language did you use to implement the multi-agent system?
2. Did you use multi-agent programming languages? Why or why not to use a 
multi-agent programming language?
3. How have you mapped the designed architecture (both multi-agent and 
individual agent architectures) to programming codes i.e., how did you 
implement specific agent-oriented concepts and designed artifacts using the 
programming language?
4. Which development platforms and tools are used? How much time did you 
invest in learning those?
5. Which runtime platforms and tools (e.g. Jade, AgentScape, simply Java, 
....) are used? How much time did you invest in learning those?
6. What features were missing in your language choice that would have 
facilitated your development task?
7. What features of your programming language has simplified your development 
task?
8. Which algorithms are used/implemented?
9. How did you distribute the agents on several machines? And if you did not 
please justify why.
10. To which extend is the reasoning of your agents synchronized with the 
receive-percepts/send-action cycle?
11. What part of the development was most difficult/complex? What kind of 
problems have you found and how are they solved?
12. How many lines of code did you write for your software?
}
\end{comment}

\subsection{Architecture implementation}

\begin{figure}
\centering
  \includegraphics[width=\textwidth]{agent_architecture2.png}
    \caption{Agent architecture in a flow chart-like diagram. 
    Dashed arrows represent process flow, solid lines represent data flow.}
\label{fig:architecture}
\end{figure}

%Aca va toda la bola de explicacion del dibujito

    The first part of the architecture is the Python part, that handles all the 
    communication with the servers. It first opens a TCP/IP connection with the 
    MASSIM server, and authenticates. Then it does the same with our Percept 
    Server, that has to be running. It waits for all the agents, and then 
    everything is set to start the simulation.

\subsubsection{Percept-act loop.}

    When the first action-request message is received, this loop starts. It 
    first processes the perception, and then sends it to the Percept Server. 
    This waits for all the other agents' perception, merges them, and then sends 
    back a new version, that cointains everything that has been seen by its
    teammates, but not by itself.
    
    This global perception is asserted into Prolog. Then, Python queries it,
    asking for an action to be performed.
    
\subsubsection{Action requested.}

    As seen in the Figure \ref{fig:architecture}, after the Python part, comes 
    all the processing in Prolog. The perception is already in the knowledge 
    base, that is formed by the ``static'' and ``dynamic'' data. 

    If the agent has already an intention stored, the \textit{cut condition} 
    checks whether it still is significant to keep doing it. It is a series of 
    simple conditions, that reviews the state of the world.

    Then, if there was not any intention, or the cut condition decides it is not 
    interesting to keep it, the \textit{beliefs setting} is started. It 
    generates the possible desires for this step, according to what is stored in 
    the knowledge base, and, for each one of them, the beliefs needed.

    The decision-taking module is implemented in DeLP, a defeasible logic 
    programming language used in argumentation. Given the set of possible 
    desires and beliefs set by the previous module, it selects the best desire, 
    returning it as the intention to be done.

    All the plans for all the desires were previously calculated and stored as 
    beliefs, since the amount of steps that they need is used by the 
    argumentation module. The \textit{planning} module selects the one 
    corresponding to the selected intention, and stores it.

    The execution module only gets the plan, and returns to Python the first 
    action in it.

    However, if the process flow comes from the other branch of \ref{
    fig:architecture}, the execution is not that simple. Since skipping the 
    decision-taking makes this branch insignificant in terms of time, we decided 
    to recalculate the plan. This might help us when a better path is 
    discovered, even though this is unlikely.

    Back again in Python, with the returned action, an XML is formed, to be sent 
    to the server.

\subsection{Programming languages, platforms and tools}

    The agent system was implemented using Python 2.7 and SWI Prolog 5.10.5. DeLP 
    \cite{Garcia:2004a}, a defeasible logic programming language, was used as a 
    service within Prolog. 
    Language integration was achieved using the pyswip library, calling Prolog 
    predicates from Python. The implementation of Defeasible Logic Programming 
    (DeLP) by the LIDIA was used for the deliberative process. They were 
    well-known at the start of the project, and were chosen for precisely those
    reasons.

    No multi-agent programming languages/patforms/frameworks were used due to 
    previous experience indicating a general lack of flexibility, and a lack of 
    familiarity on behalf of the development team.
    
    Both Linux and the Windows operating system were used as development 
    platforms, since the language runtimes chosen for implementation were 
    portable. Some caveats were encountered however.

    We used git as our revision control system. In general, we did not spend much 
    time in learning it, since some of us had already worked with it.

\subsubsection{Benefits.}
    
    Python's amenity to rapid application development and 'batteries-included 
    philosophy' facilitated implementing the communication layer to the MASSimg 
    server, parsing of peceptions, rapid addition of planned features and bug 
    correction.

    We made use of Prolog's declarative nature to model states of the world, and it 
    also made more straightforward to implement search algorithms like Uniform Cost 
    Search, and Depth First Search. The zone-coloring algorithm was also 
    implemented in Prolog.

    Initial plans were to distribute agents on several machines. Each agents runs 
    as a separate process, and communicates with others via TCP sockets. After 
    some experience and benchmarking, agents were run on one machine, due to 
    performance issues. 
    Having the choice was a benefit of the proposed design.

\subsubsection{Problems encountered.}

    The most difficult problems were related to optimization. Much of our time has 
    been spent in reducing the complexity of our algorithms, and the times they 
    are called.

    For the coloring algorithm, we added several improvements, for both 
    optimization and correctness. In essence, since we only had an incomplete 
    version of the full map in every step, we added the concept of ``fog of war`'' 
    to the agents, assuming always in a pessimistic way. 

    For both search algorithms, the Depth First Search and the Uniform Cost 
    Search, we added conditions that could cut several branches, when they were 
    expanding to unwanted nodes. This conditions were set by the caller, since 
    they depend on the context of the problem.

    For the UCS, we first used a simple stack, implemented with a list, to keep 
    track of the frontier, because of Prolog's inability to work with arrays. This 
    would have allowed us to develop a heap data structure, to be used in a 
    priority queue. Lately, we found a Prolog library that implemented this data 
    structure, and the migration was pleasently straightforward.

    Finally, for this last algorithm too, we added an important optimization, 
    that allowed us to call it several times, with the virtual cost of only one 
    call. It was done using memoization, and a more thoughtful invocation.

\section{Stategies, Details, and Statistics}

\subsection{Strategy}
    The main strategy of the team consists of detecting profitable zones from the 
    explored vertices, and positioning the agents correctly to maintain, defend 
    and expand the zones. 
    
    Our agents do not change their behavior during runtime. It is actually very 
    easy to add this feature, but we had not enough time to implement it.
    
    Achievements are not taken under consideration. However, agents can
    achieve a significant number of them, since this behavior is implicitly 
    implemented.
    
\subsubsection{Zone conquering.}
    
    If an agent is not being part of any zone, it tries to regroup with a partner. 
    When a zone is formed, and the agent is part of it, for each potentially 
    beneficial neighbor node, the agent calculates how much points would they win 
    if it moves, and that information is used by the decision taking module.
    Agents make no assumption about the map topology. They will prefer higher 
    valued nodes over lower ones.

    If the expansion intention explained is selected and carried on, then a new 
    better zone is implicitly conquered.

\subsubsection{Attacking and defending.}
    
    Both attacking and defense are implicitly implemented. Sabouteurs attack 
    enemies that are near, so they might attack them if they enter our team's 
    zone, as well as when they are in their zone. Any other agent of another role
    can go to a node that has, for example, two agents, one for each team, in order
    to expand the zone, occupying the contested node, and implicitly defending it.
    
\subsection{Implementation}

    Here are the details of the implementation of the different parts of the
    agents.

\subsubsection{Path planning.}

    Path planning is implemented with an Uniform Cost Search 
    \cite{Russell:2003:AIM:773294}. 
    What we tried to minimize was the amount of steps required to achieve the 
    goal, rather than the spent energy. 
    The returned result is the list of actions to be done, rather than the list of 
    nodes.
    
    Since this algorithm can be called several times in one step, given that the 
    actual amount of steps spent by an intention is taken under consideration by 
    the decision-taking module, it was crucial to perform several optimizations in 
    it. In the end, this allowed us to run all the agents in a single machine, 
    during the competition.
    
    The plans are as long as the selected intention requieres. This may 
    sound excesive, but the possible goals were previously selected for their 
    potential, taking into consideration their distance (in nodes, not in 
    actions). However, plans are recalculated in every step, as explained earlier.

\subsubsection{Communication.}

    Some functionality provided by the \textit{eismassim} library was
    reimplemented in a connection library in Python.

    On each perceive/act cycle, agents receive the percept from the MASSim server, 
    separate the information which will remain private and which will be shared. 
    The public part of the percept is sent to the percept server, which performs a 
    union of all percept and send the difference back to each agent. After 
    receiving the joint percept, the agents enter a belief setting phase, and 
    later an argumentation phase.
    
\subsubsection{Buying}

    Agents follow a list of predefined buying actions, when the necessary amount 
    of money is reached.
    
    Many different approaches were considered, e.g. a more thoughtful one, taking
    into consideration the amount of deaths, of our team, and of our enemy.
    However, this simple approach was the easiest to implement, and it was
    proven to be the most succesful one.

\subsection{Agents' organization}

    The only organization that the agents have is the proper given by the 
    environment, which is the roles. 
    
    Refering to our actual programming, all the agents have a strong core of common
    code, which is:
    
    \begin{itemize}
        \item all the Python part, that servers as a receive-percepts/send-action client 
        of the server,
        
        \item the Percept Server,
        
        \item an important part of the Prolog code, including all the utilities used, the
        implementation of the BDI architecture, the structure of the 
        decision-taking module, and a considerable part of the arguments used, that
        are common to all the roles.
    \end{itemize}
    
    Apart from all this, each role has a couple of separate files, that have 
    specific code, including the arguments used in the decision-taking module, and
    the setting of the beliefs needed for those arguments. Here is where the 
    individual behavior is set, since the specific actions that can be done by each
    role are being had in consideration here.
    
    Specific values for the decision-taking module for each role are also included
    in these files, and this is what can make that agents of different role act 
    differently, faced to the same situation, according to our judgment.
    
    These separation is negligible, having in consideration the amount of code 
    written for the agents, and may be near a 5\% of it. However, this has been proven to
    be more than enough to modify considerably the behavior of the agents, thanks to
    the non-monotonic nature of DeLP, the argumentation language used in the 
    decision-taking module.

\section{Conclusion}

\begin{comment}
PREGUNTAS {
1. What have you learned from the participation in the contest?
2. Which are the strong and weak points of the team?
3. How suitable was the chosen programming language, methodology, tools, and 
algorithms?
4. What can be improved in the context for next year?
5. Why did your team perform as it did? Why did the other teams perform 
better/worse than you did?
6. Which other research fields might be interested in the Multi-Agent 
Programming Contest?
7. How can the current scenario be optimized? How would those optimization pay 
off?
}
\end{comment}
    
    Our team is formed by a group of friends, so a strong point in the developing 
    process would have been the cohesion and comradeship. We had also worked 
    together, in university's projects as well as outside them, in small freelance 
    projects, so we well knew what to expect from each other, and each member's 
    capabilities. 

    Several events in the developing process had depend from this bond, i.e. the 
    deployment. We could not connect to the server in the test matches from our 
    university, because of several network problems. Just a couple of days before 
    the competition, we decided to connect all from one of our partner's house, 
    who had the better infrastructure (connection to Internet, and space in his 
    apartment). This may seem stranger given the fact that we had to spent all 
    night working and testing there, so for a week the headquarters for our team 
    also became our home.

    However, we had many problems. Many of them were related with our lack of 
    professionality, and lack of experience working in a big project. For example, 
    we had problems simple but annoying problems, such as the encoding of our 
    source files, or having different versions of the programs we used to program
    installed in our computers.

    We are really grateful with our decisions involving programming languages, 
    tools and algorithms. Of course, we had many problems, and much time was spent 
    deciding what to choose, but having all the process in consideration, we may 
    had took the right calls. We should thank the great education given by our 
    university (Universidad Nacional del Sur), and a great mentoring from our 
    professors.

    Many things should and will be improved for next year competence. We have
    gained an important amount of knowledge, capability and experience, that shall 
    help us in all aspects of the developing process, not to mention the 
    important amount of code already written, and all the good decisions already 
    made.

    In particular, we now know the importance of all the testing actually needed 
    for this sort of competition, not only in a virtual environment, as we did, 
    but also in the real context of the contest. There were several hotfixes that 
    were written and deployed at the same time we were facing our competitors, in 
    all but the last day of competition, in which we already had everything in 
    consideration and control.

    Many optimizations ocurred to us for the scenario, and the contest in general. 
    For example, more information for the nodes, including something useful for a 
    directed search (i.e., absolute coordinates), would help in the implementation 
    of a A* search, that would decrease the execution times.

    Strategically, the early dominion of the center area played an important part 
    of a good candidate to win a match. It would be useful to try other 
    variations, such as making the borders more important, or others shapes of the 
    map, such as stretched, in form of V, X, O, etc. This would benefit teams that 
    explicitly and thoughtfully look for and conquer good zones, rather than 
    benefiting teams that assume that only one good zone exists, and it's in the 
    middle of the map.

    A more informing/informational/apprising? feedback from the server would be 
    appreciated, specially involving errors. This is important for a better and 
    quicker detection of bug involving the communication, i.e. problems with the 
    connection, files sent.

    Finally, we think it will be really helpful for all that we had test matches 
    in a more early stage, in order to have more time to correct errors in the 
    client. Many of us reimplemented the eismassim module, so we are vulnerable to 
    many errors that were difficult to foresee. Early testing would help with 
    that, and detecting infrastructure issues, such as network problems.
    
    

%BIBTEX
    
\bibliographystyle{plainnat} 
\bibliography{bib} 

\end{document} 
